# Retrieval-Augmented-Generation-RAG-
This repo contains information about how RAG works

In ordinary situations with Large Language Models (LLMs) are prone to provide hallucinated responses as shown below.

![image](https://github.com/ParthaPRay/Retrieval-Augmented-Generation-RAG-/assets/1689639/74f05c3a-b459-47d0-b1f1-df36363ad6c4)



The key problems of LLMs are:
* Backdated information 
* No or lack of validation source

![image](https://github.com/ParthaPRay/Retrieval-Augmented-Generation-RAG-/assets/1689639/48d56547-539f-4142-87e4-d710e3dc8049)

Retrieval-Augmented Generation (RAG) is there to save the hallucination problem reduction among LLMs.

![image](https://github.com/ParthaPRay/Retrieval-Augmented-Generation-RAG-/assets/1689639/c2b5af34-769a-4b85-9550-2444201558f0)


Without RAG, an LLM can respond anything as below.
![image](https://github.com/ParthaPRay/Retrieval-Augmented-Generation-RAG-/assets/1689639/1cfeaa74-aa3a-4374-b074-6196584ec628)

With RAG, the LLM provides more responsible, reliable and less hallucinated responses.
![image](https://github.com/ParthaPRay/Retrieval-Augmented-Generation-RAG-/assets/1689639/1d90191d-0a2a-4454-afcf-49d13583d960)
